{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a8a946-60a8-4561-8da0-e495307df16f",
   "metadata": {},
   "source": [
    "# Offline RL Pipeline\n",
    "This notebook contains the full pipeline described in \"Optimizing Loop Diuretic Treatment in Hospitalized Patients: A Case Study in Practical Application of Offline Reinforcement Learning to Healthcare\". The code provided here is a psuedocode designed to demonstrate the full pipeline and cannot be executed on its own. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9dd9ad-fa84-40e7-b48f-0a8dba3c5c04",
   "metadata": {},
   "source": [
    "## 1. Data Partition\n",
    "- The development data is randomly split at the trajectory level into X partitions of training/validation splits"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c4cb195-55b0-4d25-a7ad-2abe6a9134bf",
   "metadata": {},
   "source": [
    "combined_ids: list of all hospitalization ids\n",
    "df_dev : development dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63762c78-3f16-4085-8dca-d5afb2ada0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_id in range(X):\n",
    "    new_val_ids = random.sample(combined_ids, 7289)\n",
    "    new_train_ids = list(set(combined_ids) - set(new_val_ids))\n",
    "\n",
    "    df_tr = df_dev[df_dev.pt_id.isin(new_train_ids)]\n",
    "    df_va = df_dev[df_dev.pt_id.isin(new_val_ids)]\n",
    "\n",
    "    df_tr.to_csv('./data_splits/split_{:03d}_tr.csv'.format(split_id), index = False)\n",
    "    df_va.to_csv('./data_splits/split_{:03d}_va.csv'.format(split_id), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50f072-bded-492e-9192-94554821abc2",
   "metadata": {},
   "source": [
    "## 2. Defining the State Space\n",
    "- A set of candidate state definitions are generated by varying the data partition and number of states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12339fc4-afaa-43d6-a999-abbc30b51c53",
   "metadata": {},
   "source": [
    "### 2.1. Creating the embeddings\n",
    "- For each data partition, learn a embedding model.\n",
    "- Then use the embedding models to create X embeddings for each data partition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6669f6-2765-4e64-a1b1-3503bf6d0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_id in range(X):\n",
    "    embedding_model = torch.load('state_{:03d}_embedding_model.pt'.format(state_id))\n",
    "    for split_id in range(X):\n",
    "        df_tr = pd.read_csv('./data_splits/split_{:03d}_tr.csv'.format(split_id))\n",
    "        df_va = pd.read_csv('./data_splits/split_{:03d}_va.csv'.format(split_id))\n",
    "        df_te = pd.read_csv('./data_splits/split_{:03d}_te.csv'.format(split_id))\n",
    "        \n",
    "        tr_embedded = embedding_model(df_tr)\n",
    "        va_embedded = embedding_model(df_va)\n",
    "        te_embedded = embedding_model(df_te)\n",
    "        \n",
    "        tr_embedded.to_pickle('./data_splits/split_{:03d}/state_{:03d}_tr_embedded.p'.format(split_id, state_id))\n",
    "        va_embedded.to_pickle('./data_splits/split_{:03d}/state_{:03d}_va_embedded.p'.format(split_id, state_id))\n",
    "        te_embedded.to_pickle('./data_splits/split_{:03d}/state_{:03d}_te_embedded.p'.format(split_id, state_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111c1c2a-d9ab-489c-9f19-86b6ad443101",
   "metadata": {},
   "source": [
    "### 2.2. Creating the discrete clustering solutions, and cluster all embeddings\n",
    "- Cluster the embedded training data (for convenience, we use the cases where split_id = state_id) and using ensemble k-means clustering.\n",
    "- Relevant code is in `pipeline/1_run_kmeans.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f61db-7cc9-44d2-b682-5e8980b641d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_id in range(X):\n",
    "    tr_embedded = pd.read_pickle('./data_splits/split_{:03d}/state_{:03d}_tr_embedded.p'.format(state_id, state_id))\n",
    "    for k in [list_of_k]:\n",
    "        # create clustering solutions\n",
    "        run_ensemble_kmeans(tr_embedded, save_dir, k, E = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9e3ab-dd56-40fd-a687-71b1bb9de5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_id in range(X):\n",
    "    for k in [list_of_k]:\n",
    "        kmeans_model = joblib.load('./kmeans_model/state_{:03d}_k_{}_model.pkl'.format(state_id, k))\n",
    "        for split_id in range(X):\n",
    "            tr_embedded = pd.read_pickle('./data_splits/split_{:03d}/state_{:03d}_tr_embedded.p'.format(state_id, state_id))\n",
    "            # predict the clusters for each embedding\n",
    "            predict_clusters_for_embedded_data(tr_embedded, kmeans_model, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41813e2-95c8-48ce-843b-0ac50b619a51",
   "metadata": {},
   "source": [
    "### 2.3. Using the clustering results, create the trajectory files\n",
    "- Convert the embedding data into trajectory files in the format of `data/ens.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7c55d-5ddf-4dd9-b227-a3eb061f3068",
   "metadata": {},
   "source": [
    "## 3. Estimate the Behavior Policy\n",
    "- `compute_behavior_policy()` from `pipeline/OPE_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c71c6-c204-4ef1-a1fb-0c1587eb0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_id in range(X):\n",
    "    for state_id in range(X):\n",
    "        for k in [list_of_k]:\n",
    "            \n",
    "            df_va = pd.read_csv('./data_splits/split_{:03d}/state_{:03d)_k_{}/val_ens.csv'.format(split_id, state_id, k))\n",
    "            pi_b_va = compute_behavior_policy(df_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e06b5-3850-486b-9989-742366377a17",
   "metadata": {},
   "source": [
    "## 4. Training the RL Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12970c47-59c3-4b8d-940e-d25e598a79e9",
   "metadata": {},
   "source": [
    "### 4.1. Create the environment\n",
    "- Learn the transition and reward functions from the environment. \n",
    "- Use functions in `2_run_environment.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835722e5-fe36-4e6a-9a01-8bb2694f11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [0.1, 0.15, 0.2, 0.3]\n",
    "\n",
    "for split_id in range(X):\n",
    "    for state_id in range(X):\n",
    "        for k in [list_of_k]:\n",
    "            df_tr = pd.read_csv('./data_splits/split_{:03d}/state_{:03d)_k_{}/train_ens.csv'.format(split_id, state_id, k))\n",
    "            # Functions from 2_run_environment.py. df_tr will be passed to each of these functions\n",
    "            # Refer to that for more information.\n",
    "            create_transitions()\n",
    "            create_dictionary()\n",
    "            create_uncertainty_transitions()\n",
    "            create_pMDP_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb564f78-6c0b-4729-8aa6-1b8b48d95be3",
   "metadata": {},
   "source": [
    "### 4.2 Train the policies\n",
    "- Use functions in `3_run_train_policy.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337c7d6-e4cf-4e3b-a2bf-4f3fcd14273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_id in range(X):\n",
    "    for state_id in range(X):\n",
    "        for k in [list_of_k]:\n",
    "            # For each train_ens.csv, iterate through all the parameters for training the policy\n",
    "            # Refer to functions in 3_run_train_policy.py for more information\n",
    "            generate_Q_masks()\n",
    "            train_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed514494-8df2-4b9b-ab9b-882b4a9432a6",
   "metadata": {},
   "source": [
    "## 5. Final Policy Selection and Evaluation\n",
    "- Evaluate all the policies for each `train_ens.csv` using functions in `4_run_evaluation.py`\n",
    "- Aggregate the results and select the best hyperparameter (not shown here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374e255-bf8b-494e-947f-d3814ea48a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_id in range(X):\n",
    "    for state_id in range(X):\n",
    "        for k in [list_of_k]:\n",
    "            # For each train_ens.csv, evaluate all the policies generated using that training data\n",
    "            evaluate_policy_for_each_setting(df_va, df_te, main_dir, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
